{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dir_data_2023 = Path('data/processed_2023')\n",
    "dir_data_2024 = Path('data/processed_2024')\n",
    "dir_data_merged = Path('data/processed_merged')\n",
    "def parse_filename(file_path):\n",
    "    parts = file_path.stem.split('_')\n",
    "    sample_indx = int(parts[0])\n",
    "    label = parts[1]\n",
    "    start = parts[2]\n",
    "    end = parts[4]\n",
    "    return sample_indx, label, start, end\n",
    "def sum_dataset(dir_data):\n",
    "    dir_data = Path(dir_data)  # Ensure dir_data is a Path object\n",
    "    filespath = dir_data.glob('*.csv')\n",
    "    all_dataset = {}\n",
    "\n",
    "    for path in filespath:\n",
    "        _, label,_,_= parse_filename(path)\n",
    "        if label in all_dataset:\n",
    "            all_dataset[label] += 1\n",
    "        else:\n",
    "            all_dataset[label] = 1\n",
    "\n",
    "    # Creating a DataFrame from the dictionary\n",
    "    sum_df = pd.DataFrame(list(all_dataset.items()), columns=['Label', 'Count'])\n",
    "    return sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Label  Count\n",
      "1        CTC4  15702\n",
      "2    RB966928   5875\n",
      "6     CTC9003   4791\n",
      "8     CTC9001   4372\n",
      "0     CTC9002   3130\n",
      "5    RB975242   2007\n",
      "4      CV7870   1797\n",
      "12   RB867515   1745\n",
      "7    RB975201   1404\n",
      "10   RB985476   1310\n",
      "13    CTC2994   1297\n",
      "9       CTC20   1229\n",
      "3    RB975033   1169\n",
      "11  CTC9005HP   1150\n"
     ]
    }
   ],
   "source": [
    "dir_data_2024 = sum_dataset(dir_data_2024)\n",
    "# sort the dataframe by count\n",
    "dir_data_2024 = dir_data_2024.sort_values(by='Count', ascending=False)\n",
    "print(dir_data_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def merge_csv_files_based_on_dates(dir1, dir2, output_dir):\n",
    "    dir1 = Path(dir1)\n",
    "    dir2 = Path(dir2)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create a dictionary to track files by identifiers\n",
    "    file_map = {}\n",
    "\n",
    "    # Process all files in both directories\n",
    "    for directory in [dir1, dir2]:\n",
    "        for file_path in directory.glob('*.csv'):\n",
    "            sample_indx, label, start, end= parse_filename(file_path)\n",
    "            identifier = f'{sample_indx}_{label}'\n",
    "            if identifier in file_map:\n",
    "                file_map[identifier].append(file_path)\n",
    "            else:\n",
    "                file_map[identifier] = [file_path]\n",
    "\n",
    "    # Merge files that have the same identifier\n",
    "    bar = tqdm(file_map.items(), desc='Merging files')\n",
    "    for identifier, files in bar:\n",
    "        if len(files) > 1:\n",
    "\n",
    "            dataframes = [pd.read_csv(f) for f in files]\n",
    "            merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "            merged_df['SourceFile_Start_Date'] = merged_df['SourceFile'].apply(extract_start_date)\n",
    "            merged_df.sort_values(by='SourceFile_Start_Date', inplace=True)\n",
    "            merged_df.drop(columns=['SourceFile_Start_Date'], inplace=True) \n",
    "\n",
    "            merged_filename = f\"{identifier}.csv\"\n",
    "            merged_df.to_csv(output_dir / merged_filename, index=False)\n",
    "            # print(f\"Merged file saved: {output_dir / merged_filename}\")\n",
    "        bar.set_postfix_str(f'Num of processed files: {len(file_map)}')\n",
    "def extract_start_date(source_file):\n",
    "    start_date = source_file.split('_to_')[0]\n",
    "    return pd.to_datetime(start_date)\n",
    "# Example usage\n",
    "merge_csv_files_based_on_dates(\n",
    "    'data/processed_2023',\n",
    "    'data/processed_2024',\n",
    "    'data/processed_merged'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = list(df.groupby('SourceFile'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2023-05-13_to_2023-05-19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Band_1</th>\n",
       "      <th>Band_2</th>\n",
       "      <th>Band_3</th>\n",
       "      <th>Band_4</th>\n",
       "      <th>Band_5</th>\n",
       "      <th>Band_6</th>\n",
       "      <th>Band_7</th>\n",
       "      <th>Band_8</th>\n",
       "      <th>Band_9</th>\n",
       "      <th>Band_10</th>\n",
       "      <th>Band_11</th>\n",
       "      <th>Band_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>51</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Band_1  Band_2  Band_3  Band_4  Band_5  Band_6  Band_7  Band_8  Band_9  \\\n",
       "1104       6       9      18      24      34      57      61      62      61   \n",
       "1105       6       9      17      21      31      58      64      64      65   \n",
       "1106       6       8      16      17      29      58      66      67      68   \n",
       "1107       6       8      15      18      28      57      66      68      67   \n",
       "1108       6       8      16      18      29      57      66      66      67   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1283       6       8      17      21      31      55      63      63      64   \n",
       "1284       6       8      16      18      29      56      64      65      66   \n",
       "1285       7      10      18      20      30      58      65      66      68   \n",
       "1286       4       8      16      18      28      58      68      69      72   \n",
       "1287       7       9      17      19      29      58      67      67      68   \n",
       "\n",
       "      Band_10  Band_11  Band_12  \n",
       "1104       65       51       39  \n",
       "1105       65       49       35  \n",
       "1106       65       48       33  \n",
       "1107       66       48       34  \n",
       "1108       66       49       35  \n",
       "...       ...      ...      ...  \n",
       "1283       64       51       39  \n",
       "1284       65       49       36  \n",
       "1285       69       52       37  \n",
       "1286       72       48       27  \n",
       "1287       69       51       35  \n",
       "\n",
       "[184 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 6\n",
    "time = weekly_data[i][0]\n",
    "data = weekly_data[i][1].iloc[:,4:-2]\n",
    "print(f\"Time: {time}\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "def random_time_bins_selction(band_data):\n",
    "    dates = pd.to_datetime(band_data.time.values)\n",
    "\n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    df = pd.DataFrame({'date': dates})\n",
    "\n",
    "    # Extract year and month for grouping\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "\n",
    "    # Group by year and month, then randomly select one observation from each group\n",
    "    return df.groupby(['year', 'month']).apply(lambda x: np.random.choice(x.index)).tolist()\n",
    "def get_data_time(self, df):\n",
    "    \n",
    "\n",
    "    all_month_data = np.zeros((12, self.num_bands, self.patch_height, self.patch_width))\n",
    "    all_day = np.array(pd.date_range(start=f'{netcdf.patch_year}-01-01', end=f'{int(netcdf.patch_year) + 1}-01-01', freq=self.group_freq).dayofyear)[:-1]\n",
    "\n",
    "    data = []\n",
    "    day = []\n",
    "    month    = []\n",
    "    for band_id, band in enumerate(self.bands):\n",
    "        # Load band data\n",
    "        band_data    = xr.open_dataset(xr.backends.NetCDF4DataStore(netcdf[band]))\n",
    "\n",
    "        selected_idx = random_time_bins_selction(band_data)\n",
    "\n",
    "        d = band_data.to_array().values[:,selected_idx]\n",
    "        t = band_data.time.values[selected_idx]\n",
    "        \n",
    "        expand_ratio = int(BANDS[band] / BANDS[REFERENCE_BAND])\n",
    "        if expand_ratio != 1:\n",
    "            d = np.repeat(d, expand_ratio, axis=-1)\n",
    "            d = np.repeat(d, expand_ratio, axis=-2)\n",
    "\n",
    "        data.append(d)\n",
    "        day.append(pd.to_datetime(t).dayofyear)\n",
    "        month.append(pd.to_datetime(t).month)\n",
    "\n",
    "    data = np.concatenate(data).transpose(1, 0, 2, 3)\n",
    "    month = np.stack(month).mean(axis = 0,dtype = int)\n",
    "\n",
    "    day = np.stack(day).mean(axis=0)\n",
    "\n",
    "    all_month_data[month-1] = data\n",
    "    all_day[month-1] = day\n",
    "    return all_month_data, all_day/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = list(dir_data_merged.glob('*.csv'))[0]\n",
    "df = pd.read_csv(path_data)\n",
    "\n",
    "def extract_interesting_data(df, bands):\n",
    "    # Extract the starting date from the SourceFile column\n",
    "    df['StartDate'] = df['SourceFile'].apply(lambda x: x.split('_to_')[0])\n",
    "    \n",
    "    # Convert StartDate to datetime to extract the week of the year\n",
    "    df['WeekOfYear'] = pd.to_datetime(df['StartDate']).dt.isocalendar().week\n",
    "    \n",
    "    # Calculate week of the year divided by 52 to get the fraction of the year\n",
    "    df['WeekFraction'] = df['WeekOfYear'] / 52\n",
    "    \n",
    "    # Filter the dataframe to include only the specified bands and the new WeekFraction column\n",
    "    columns_of_interest = bands + ['WeekFraction']\n",
    "    filtered_df = df[columns_of_interest]\n",
    "    \n",
    "    return filtered_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import interp1d\n",
    "def interpolate_along_axis(data, axis=1):\n",
    "    # Interpolate along the specified axis for each slice in the other dimensions\n",
    "    shape = data.shape\n",
    "    # Iterate over the first and third dimension, interpolating along the second\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[2]):\n",
    "            # Extract the line to interpolate\n",
    "            line = data[i, :, j]\n",
    "            # Find indices where data is non-zero\n",
    "            if np.any(line):  # Check if there's at least some non-zero data to interpolate\n",
    "                indices = np.arange(len(line))\n",
    "                good_data = line != 0\n",
    "                # Create an interpolation function based on non-zero data\n",
    "                f = interp1d(indices[good_data], line[good_data], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "                # Interpolate missing data\n",
    "                data[i, :, j] = f(indices)\n",
    "            # Optionally handle cases where the entire line is zero by setting a default or carrying forward last known good data\n",
    "\n",
    "    return data\n",
    "def extract_interesting_data(df, bands):\n",
    "    # Extract the starting date from the SourceFile column\n",
    "    df['StartDate'] = df['SourceFile'].apply(lambda x: x.split('_to_')[0])\n",
    "    \n",
    "    # Convert StartDate to datetime to extract the week of the year\n",
    "    df['WeekOfYear'] = pd.to_datetime(df['StartDate']).dt.isocalendar().week\n",
    "    \n",
    "    # Calculate week of the year divided by 52 to get the fraction of the year\n",
    "    df['WeekFraction'] = df['WeekOfYear'] / 52\n",
    "    \n",
    "    df['MonthOfYear'] = pd.to_datetime(df['StartDate']).dt.month\n",
    "    df['MonthOfYear'] = df['MonthOfYear'] / 12\n",
    "    # Filter the dataframe to include only the specified bands and the new WeekFraction column\n",
    "    columns_of_interest = bands + ['WeekFraction'] + ['MonthOfYear'] + ['StartDate']\n",
    "    filtered_df = df[columns_of_interest]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def split_data(all_dataset, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    if train_ratio + val_ratio + test_ratio != 1:\n",
    "        raise ValueError(\"Sum of ratios must be equal to 1\")\n",
    "\n",
    "    # Initialize dictionaries for train, val, and test sets\n",
    "    train_set = {}\n",
    "    val_set = {}\n",
    "    test_set = {}\n",
    "\n",
    "    for label, paths in all_dataset.items():\n",
    "        # Shuffle paths to ensure randomness\n",
    "        random.shuffle(paths)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        n_total = len(paths)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        \n",
    "        # Create splits\n",
    "        train_paths = paths[:n_train]\n",
    "        val_paths = paths[n_train:n_train + n_val]\n",
    "        test_paths = paths[n_train + n_val:]\n",
    "\n",
    "        # Store paths by label in the respective dictionaries\n",
    "        train_set[label] = train_paths\n",
    "        val_set[label] = val_paths\n",
    "        test_set[label] = test_paths\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "def parse_filename(file_path):\n",
    "    parts = file_path.stem.split('_')\n",
    "    sample_indx = int(parts[0])\n",
    "    label = parts[1]\n",
    "    return sample_indx, label\n",
    "\n",
    "def sum_dataset(dir_data):\n",
    "    dir_data = Path(dir_data)  # Ensure dir_data is a Path object\n",
    "    filespath = dir_data.glob('*.csv')\n",
    "    all_dataset = {}\n",
    "\n",
    "    for path in filespath:\n",
    "        _, label= parse_filename(path)\n",
    "        if label in all_dataset:\n",
    "            all_dataset[label].append(path)\n",
    "        else:\n",
    "            all_dataset[label] = []\n",
    "    return all_dataset\n",
    "def remove_zero_rows(df, band_columns ):\n",
    "    # Specify the band columns to check for zeros\n",
    "    \n",
    "    \n",
    "    # Check if all values in these columns are zero\n",
    "    mask = (df[band_columns] == 0).all(axis=1)\n",
    "    \n",
    "    # Filter out rows where all band values are zero\n",
    "    filtered_df = df[~mask]\n",
    "    \n",
    "    return filtered_df\n",
    "def compute_monthly_median(df):\n",
    "    # Create a copy of the dataframe to avoid modifying the original inadvertently\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert the 'StartDate' column to datetime\n",
    "    df_copy['StartDate'] = pd.to_datetime(df_copy['StartDate'])\n",
    "\n",
    "    # Set 'StartDate' as the index of the dataframe\n",
    "    df_copy.set_index('StartDate', inplace=True)\n",
    "    \n",
    "    # Resample data by month and calculate the median\n",
    "    monthly_median = df_copy.resample('M').median()\n",
    "\n",
    "    return monthly_median\n",
    "def compute_median_of_each_month(filtered_df, interested_bands):\n",
    "    allmonth_data = {}\n",
    "    all_month = []\n",
    "    for start_date, group in filtered_df.groupby('StartDate'):\n",
    "\n",
    "        year = pd.to_datetime(start_date).year\n",
    "        month = pd.to_datetime(start_date).month\n",
    "        # print(start_date)\n",
    "        # print(year)\n",
    "        # print(month)\n",
    "        # print(group[interested_bands].values.shape)\n",
    "        key = f'{year}_{month}_{month/12}'\n",
    "        data = group[interested_bands].values\n",
    "        if key in allmonth_data:\n",
    "            allmonth_data[key].append(data)\n",
    "        else:\n",
    "            allmonth_data[key] = [data]\n",
    "    for key, data in allmonth_data.items():\n",
    "        data = np.stack(data)\n",
    "        median = np.median(data, axis=0)\n",
    "        #  replace the value in the key with the median value\n",
    "        allmonth_data[key] = median\n",
    "        all_month.append(int(key.split('_')[1])/12)\n",
    "    return allmonth_data, np.array(all_month)\n",
    "save_dir = Path('data/ctc_dataset')\n",
    "\n",
    "source_dir = Path('data/processed_merged')\n",
    "all_dataset = sum_dataset(source_dir)\n",
    "train_set, val_set, test_set = split_data(all_dataset)\n",
    "\n",
    "splited_dataset = {'train': train_set, 'val': val_set, 'test': test_set}\n",
    "for mode in ['train', 'val', 'test']:\n",
    "    data_paths_dict = splited_dataset[mode]\n",
    "    all_labels = list(data_paths_dict.keys())\n",
    "    bar = tqdm(all_labels, desc=f'Processing {mode} data')\n",
    "    for label in bar:\n",
    "        data_paths = data_paths_dict[label]\n",
    "        for i, path in enumerate(data_paths):\n",
    "\n",
    "            save_path_data = save_dir / mode / label / f'data_{i}'\n",
    "            save_path_time = save_dir / mode / label / f'time_{i}'\n",
    "            save_path_data.parent.mkdir(parents=True, exist_ok=True)\n",
    "            save_path_time.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if save_path_data.with_suffix('.npy').exists() and save_path_time.with_suffix('.npy').exists():\n",
    "                continue\n",
    "            source_df = pd.read_csv(path)\n",
    "            if source_df.empty:\n",
    "                continue\n",
    "            try:\n",
    "                interested_bands = [f'Band_{i}' for i in range(1, 13)]\n",
    "\n",
    "                filtered_df = extract_interesting_data(source_df, interested_bands)\n",
    "\n",
    "                filtered_df, time = compute_median_of_each_month(filtered_df, interested_bands)\n",
    "\n",
    "                data = np.stack(list(filtered_df.values()),axis = 1)\n",
    "                assert data.shape[1:] == (16,12), f\"Data for {label} is not complete, as it has shape of {data.shape}\"\n",
    "\n",
    "                # #     # Save the data to .npy files\n",
    "                np.save(save_path_data.with_suffix('.npy'), data)\n",
    "                np.save(save_path_time.with_suffix('.npy'), time)\n",
    "                bar.set_postfix_str(f'Processed {i} data')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {path}\")\n",
    "                print(e)\n",
    "                continue\n",
    "    #         break\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_samples(splited_dataset):\n",
    "    \"\"\"\n",
    "    Count the number of data samples in each of the train, test, and val sets across all labels.\n",
    "    \n",
    "    Args:\n",
    "    splited_dataset (dict): A dictionary where the keys are 'train', 'test', 'val',\n",
    "                            and values are dictionaries with labels as keys and lists of data paths as values.\n",
    "                            \n",
    "    Returns:\n",
    "    dict: A dictionary with keys 'train', 'test', 'val' and values being the total number of data samples.\n",
    "    \"\"\"\n",
    "    # Initialize counts\n",
    "    counts = {'train': 0, 'test': 0, 'val': 0}\n",
    "    \n",
    "    # Iterate over each set in the dictionary ('train', 'test', 'val')\n",
    "    for set_name in ['train', 'test', 'val']:\n",
    "        # Check if the set name key exists in the dictionary\n",
    "        if set_name in splited_dataset:\n",
    "            # Iterate over each label in the set\n",
    "            for label in splited_dataset[set_name]:\n",
    "                # Accumulate the count of data paths for each label\n",
    "                counts[set_name] += len(splited_dataset[set_name][label])\n",
    "    \n",
    "    return counts\n",
    "counts = count_data_samples(splited_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 37564, 'test': 4710, 'val': 4689}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46963"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37564 + 4710 +4689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def pick_spread_months(df, num_rows=12):\n",
    "    # Ensure dataframe is sorted by 'MonthOfYear'\n",
    "    df_sorted = df.sort_values(by='MonthOfYear')\n",
    "\n",
    "    # Calculate bin size\n",
    "    num_bins = num_rows  # aiming to pick one from each bin if possible\n",
    "    bin_size = len(df_sorted) // num_bins\n",
    "\n",
    "    # Select one row from each bin\n",
    "    selected_indices = []\n",
    "    for i in range(num_bins):\n",
    "        start_idx = i * bin_size\n",
    "        if i == num_bins - 1:  # For the last bin, include all remaining rows\n",
    "            end_idx = len(df_sorted)\n",
    "        else:\n",
    "            end_idx = start_idx + bin_size\n",
    "\n",
    "        # Pick a row randomly from each bin or pick the middle one to ensure spread\n",
    "        middle_idx = (start_idx + end_idx) // 2\n",
    "        selected_indices.append(middle_idx)\n",
    "\n",
    "    # Select the rows\n",
    "    selected_rows = df_sorted.iloc[selected_indices]\n",
    "\n",
    "    # Since bins might not perfectly align with the number of desired rows,\n",
    "    # pick the closest unique months till you get the desired count\n",
    "    final_selected = selected_rows.drop_duplicates(subset='MonthOfYear').head(num_rows)\n",
    "\n",
    "    # If we have fewer than needed because of duplicates, fill in from other rows not picked initially\n",
    "    if len(final_selected) < num_rows:\n",
    "        extra_needed = num_rows - len(final_selected)\n",
    "        additional_rows = df_sorted[~df_sorted.index.isin(final_selected.index)].drop_duplicates(subset='MonthOfYear').head(extra_needed)\n",
    "        final_selected = pd.concat([final_selected, additional_rows])\n",
    "\n",
    "    return final_selected\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.read_csv('path_to_your_file.csv')  # Load your dataframe here\n",
    "selected_rows = pick_spread_months(filtered_df)\n",
    "# print(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekFraction</th>\n",
       "      <th>Band_1</th>\n",
       "      <th>Band_2</th>\n",
       "      <th>Band_3</th>\n",
       "      <th>Band_4</th>\n",
       "      <th>Band_5</th>\n",
       "      <th>Band_6</th>\n",
       "      <th>Band_7</th>\n",
       "      <th>Band_8</th>\n",
       "      <th>Band_9</th>\n",
       "      <th>Band_10</th>\n",
       "      <th>Band_11</th>\n",
       "      <th>Band_12</th>\n",
       "      <th>MonthOfYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038462</td>\n",
       "      <td>12.878788</td>\n",
       "      <td>16.030303</td>\n",
       "      <td>25.393939</td>\n",
       "      <td>20.575758</td>\n",
       "      <td>37.939394</td>\n",
       "      <td>99.424242</td>\n",
       "      <td>131.151515</td>\n",
       "      <td>125.818182</td>\n",
       "      <td>138.848485</td>\n",
       "      <td>133.727273</td>\n",
       "      <td>76.757576</td>\n",
       "      <td>43.272727</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>6.212121</td>\n",
       "      <td>8.575758</td>\n",
       "      <td>17.303030</td>\n",
       "      <td>13.757576</td>\n",
       "      <td>27.454545</td>\n",
       "      <td>79.060606</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>96.787879</td>\n",
       "      <td>102.393939</td>\n",
       "      <td>101.212121</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>30.727273</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>6.212121</td>\n",
       "      <td>7.575758</td>\n",
       "      <td>15.818182</td>\n",
       "      <td>12.272727</td>\n",
       "      <td>25.090909</td>\n",
       "      <td>75.333333</td>\n",
       "      <td>93.060606</td>\n",
       "      <td>91.090909</td>\n",
       "      <td>98.909091</td>\n",
       "      <td>97.121212</td>\n",
       "      <td>50.060606</td>\n",
       "      <td>26.393939</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>5.772727</td>\n",
       "      <td>8.772727</td>\n",
       "      <td>16.469697</td>\n",
       "      <td>13.121212</td>\n",
       "      <td>26.363636</td>\n",
       "      <td>74.439394</td>\n",
       "      <td>93.636364</td>\n",
       "      <td>94.242424</td>\n",
       "      <td>99.787879</td>\n",
       "      <td>98.075758</td>\n",
       "      <td>50.439394</td>\n",
       "      <td>25.939394</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>5.272727</td>\n",
       "      <td>9.515152</td>\n",
       "      <td>18.772727</td>\n",
       "      <td>15.606061</td>\n",
       "      <td>30.863636</td>\n",
       "      <td>79.287879</td>\n",
       "      <td>96.530303</td>\n",
       "      <td>100.196970</td>\n",
       "      <td>103.106061</td>\n",
       "      <td>101.969697</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>28.151515</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.423077</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>9.272727</td>\n",
       "      <td>17.984848</td>\n",
       "      <td>14.818182</td>\n",
       "      <td>28.833333</td>\n",
       "      <td>73.984848</td>\n",
       "      <td>89.909091</td>\n",
       "      <td>92.424242</td>\n",
       "      <td>95.984848</td>\n",
       "      <td>94.984848</td>\n",
       "      <td>51.121212</td>\n",
       "      <td>27.242424</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.227273</td>\n",
       "      <td>9.803030</td>\n",
       "      <td>18.984848</td>\n",
       "      <td>16.318182</td>\n",
       "      <td>31.757576</td>\n",
       "      <td>73.984848</td>\n",
       "      <td>88.984848</td>\n",
       "      <td>91.636364</td>\n",
       "      <td>95.590909</td>\n",
       "      <td>94.909091</td>\n",
       "      <td>47.939394</td>\n",
       "      <td>25.227273</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.557692</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>20.378788</td>\n",
       "      <td>20.227273</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>70.166667</td>\n",
       "      <td>83.818182</td>\n",
       "      <td>86.090909</td>\n",
       "      <td>90.424242</td>\n",
       "      <td>89.954545</td>\n",
       "      <td>55.439394</td>\n",
       "      <td>31.196970</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>6.969697</td>\n",
       "      <td>11.212121</td>\n",
       "      <td>19.242424</td>\n",
       "      <td>16.878788</td>\n",
       "      <td>30.878788</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>89.515152</td>\n",
       "      <td>91.424242</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>93.787879</td>\n",
       "      <td>51.242424</td>\n",
       "      <td>28.030303</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.711538</td>\n",
       "      <td>11.484848</td>\n",
       "      <td>13.484848</td>\n",
       "      <td>21.969697</td>\n",
       "      <td>20.969697</td>\n",
       "      <td>34.909091</td>\n",
       "      <td>70.545455</td>\n",
       "      <td>82.545455</td>\n",
       "      <td>83.090909</td>\n",
       "      <td>89.757576</td>\n",
       "      <td>88.909091</td>\n",
       "      <td>58.212121</td>\n",
       "      <td>32.727273</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.865385</td>\n",
       "      <td>19.484848</td>\n",
       "      <td>28.575758</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>57.939394</td>\n",
       "      <td>72.545455</td>\n",
       "      <td>86.272727</td>\n",
       "      <td>96.606061</td>\n",
       "      <td>98.303030</td>\n",
       "      <td>106.909091</td>\n",
       "      <td>106.545455</td>\n",
       "      <td>130.151515</td>\n",
       "      <td>92.151515</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>8.757576</td>\n",
       "      <td>11.878788</td>\n",
       "      <td>19.303030</td>\n",
       "      <td>17.545455</td>\n",
       "      <td>30.757576</td>\n",
       "      <td>74.939394</td>\n",
       "      <td>95.363636</td>\n",
       "      <td>92.909091</td>\n",
       "      <td>100.606061</td>\n",
       "      <td>99.121212</td>\n",
       "      <td>64.272727</td>\n",
       "      <td>38.636364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WeekFraction     Band_1     Band_2     Band_3     Band_4     Band_5  \\\n",
       "1       0.038462  12.878788  16.030303  25.393939  20.575758  37.939394   \n",
       "4       0.115385   6.212121   8.575758  17.303030  13.757576  27.454545   \n",
       "7       0.192308   6.212121   7.575758  15.818182  12.272727  25.090909   \n",
       "13      0.326923   5.772727   8.772727  16.469697  13.121212  26.363636   \n",
       "16      0.384615   5.272727   9.515152  18.772727  15.606061  30.863636   \n",
       "18      0.423077   5.666667   9.272727  17.984848  14.818182  28.833333   \n",
       "22      0.500000   5.227273   9.803030  18.984848  16.318182  31.757576   \n",
       "25      0.557692   6.909091  11.333333  20.378788  20.227273  34.666667   \n",
       "28      0.615385   6.969697  11.212121  19.242424  16.878788  30.878788   \n",
       "33      0.711538  11.484848  13.484848  21.969697  20.969697  34.909091   \n",
       "39      0.865385  19.484848  28.575758  40.666667  57.939394  72.545455   \n",
       "0       0.019231   8.757576  11.878788  19.303030  17.545455  30.757576   \n",
       "\n",
       "       Band_6      Band_7      Band_8      Band_9     Band_10     Band_11  \\\n",
       "1   99.424242  131.151515  125.818182  138.848485  133.727273   76.757576   \n",
       "4   79.060606   97.000000   96.787879  102.393939  101.212121   55.666667   \n",
       "7   75.333333   93.060606   91.090909   98.909091   97.121212   50.060606   \n",
       "13  74.439394   93.636364   94.242424   99.787879   98.075758   50.439394   \n",
       "16  79.287879   96.530303  100.196970  103.106061  101.969697   53.333333   \n",
       "18  73.984848   89.909091   92.424242   95.984848   94.984848   51.121212   \n",
       "22  73.984848   88.984848   91.636364   95.590909   94.909091   47.939394   \n",
       "25  70.166667   83.818182   86.090909   90.424242   89.954545   55.439394   \n",
       "28  72.333333   89.515152   91.424242   95.666667   93.787879   51.242424   \n",
       "33  70.545455   82.545455   83.090909   89.757576   88.909091   58.212121   \n",
       "39  86.272727   96.606061   98.303030  106.909091  106.545455  130.151515   \n",
       "0   74.939394   95.363636   92.909091  100.606061   99.121212   64.272727   \n",
       "\n",
       "      Band_12  MonthOfYear  \n",
       "1   43.272727          1.0  \n",
       "4   30.727273          2.0  \n",
       "7   26.393939          3.0  \n",
       "13  25.939394          4.0  \n",
       "16  28.151515          5.0  \n",
       "18  27.242424          6.0  \n",
       "22  25.227273          6.5  \n",
       "25  31.196970          7.0  \n",
       "28  28.030303          8.0  \n",
       "33  32.727273          9.0  \n",
       "39  92.151515         11.0  \n",
       "0   38.636364          1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_rows['MonthOfYear'] = selected_rows['MonthOfYear'] * 12\n",
    "selected_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week Fraction: 0.019230769230769232\n",
      "Band_1            9.222222\n",
      "Band_2           10.444444\n",
      "Band_3           19.666667\n",
      "Band_4           17.527778\n",
      "Band_5           30.833333\n",
      "Band_6           79.861111\n",
      "Band_7           99.888889\n",
      "Band_8           98.333333\n",
      "Band_9          105.388889\n",
      "Band_10         103.250000\n",
      "Band_11          56.638889\n",
      "Band_12          33.777778\n",
      "WeekFraction      0.019231\n",
      "dtype: float64\n",
      "Band_1            8.000000\n",
      "Band_2            9.000000\n",
      "Band_3           18.000000\n",
      "Band_4           13.500000\n",
      "Band_5           27.000000\n",
      "Band_6           80.000000\n",
      "Band_7          102.000000\n",
      "Band_8          100.000000\n",
      "Band_9          108.000000\n",
      "Band_10         106.000000\n",
      "Band_11          50.000000\n",
      "Band_12          27.500000\n",
      "WeekFraction      0.019231\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group the data by the week fraction, and print the first group\n",
    "for i, (week_fraction, group) in enumerate(filtered_df.groupby('WeekFraction')):\n",
    "    if i == 0:\n",
    "        print(f'Week Fraction: {week_fraction}')\n",
    "        # print(group)\n",
    "        # take the median of the group\n",
    "        print(group.mean())\n",
    "        print(group.median())\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropcls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
